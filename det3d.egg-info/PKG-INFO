Metadata-Version: 1.1
Name: det3d
Version: 1.0rc0+530c79c
Summary: det3d: A General 3D Object Detection Codebase
Home-page: https://github.com/poodarchu/det3d
Author: Benjin Zhu
Author-email: poodarchu@gmail.com
License: Apache License 2.0
Description: det3d
        ==============================
        
        MEGVII's pytorch version 3D object detection codebase.
        
        Project Organization
        ------------
        ```
        .
        ├── examples   -- all supported models
        ├── docs
        ├── lib
        ├── LICENSE
        ├── README.md
        ├── requirements.txt
        ├── scripts
        └── utils
        ```
        
        Prerequisite
        -------------------
        ## 0. Requirements
        - Pytorch 1.1
        - Python 3.6+
        
        ## 1. Clone the project
        ```
        git clone --recursive git@git-core.megvii-inc.com:zhubenjin/det3d.git
        ```
        ## 2. Install dependencies
        ```
        cd det3d
        bash tools/build.sh
        ```
        
        ## 3. Setup Environments
        ```
        export PATH=/path/to/your/cmake-3.13.4-Linux-x86_64/bin:$PATH
        export PATH=/path/to/your/.local/bin:$PATH
        
        export CUDA_HOME=/data/cuda/cuda-10.0/cuda
        export PATH=/data/cuda/cuda-10.0/cuda/bin:$PATH
        export LD_LIBRARY_PATH=/data/cuda/cuda-10.0/cuda/lib64:/data/cuda/cuda-10.0/cudnn/v7.5.0/lib64:$LD_LIBRARY_PATH
        
        export CUDNN_LIBRARY=/data/cuda/cuda-10.0/cudnn/v7.5.0/lib64/libcudnn.so.7.5.0
        export CUDNN_INCLUDE_DIR=/data/cuda/cuda-10.0/cudnn/v7.5.0/include
        
        # export NUMBAPRO_CUDA_DRIVER=/usr/lib/nvidia/lib64/libcuda.so
        unset NUMBAPRO_CUDA_DRIVER
        export NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so
        export NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice
        
        alias watchgpu='watch -n 0.1 nvidia-smi'
        
        # export TMPDIR=/home/zhubenjin/data/tmp
        unset TMPDIR
        
        export PATH=/path/to/your/anaconda3/bin:$PATH
        
        alias oss="aws --endpoint-url=http://oss.hh-b.brainpp.cn s3"
        alias v100="rlaunch --group R4D_Detection --cpu 64 --gpu 8 --memory 376000 -- zsh"
        alias 2080ti="rlaunch --cpu 64 --gpu 8 --memory 376000 -- zsh"
        ```
        
        Data Preparation
        -----------------
        ## 1. download data and organise as follows
        ```
        # For KITTI Dataset
        └── KITTI_DATASET_ROOT
               ├── training    <-- 7481 train data
               |   ├── image_2 <-- for visualization
               |   ├── calib
               |   ├── label_2
               |   ├── velodyne
               |   └── velodyne_reduced <-- empty directory
               └── testing     <-- 7580 test data
                   ├── image_2 <-- for visualization
                   ├── calib
                   ├── velodyne
                   └── velodyne_reduced <-- empty directory
        
        # For nuScenes Dataset         
        └── NUSCENES_TRAINVAL_DATASET_ROOT
               ├── samples       <-- key frames
               ├── sweeps        <-- frames without annotation
               ├── maps          <-- unused
               └── v1.0-trainval <-- metadata and annotations
        └── NUSCENES_TEST_DATASET_ROOT
               ├── samples       <-- key frames
               ├── sweeps        <-- frames without annotation
               ├── maps          <-- unused
               └── v1.0-test     <-- metadata
        ```
        ## 2. Convert to pkls
        ```
        # KITTI
        python create_data.py kitti_data_prep --root_path=KITTI_DATASET_ROOT
        # nuScenes
        python create_data.py nuscenes_data_prep --root_path=NUSCENES_TRAINVAL_DATASET_ROOT --version="v1.0-trainval" --nsweeps=10
        python create_data.py nuscenes_data_prep --root_path=NUSCENES_TEST_DATASET_ROOT --version="v1.0-test" --nsweeps=10
        ```
        ## 3. Modify configs
        Modify dataset pkl file path in src/configs/xxx.config:
        ```
        DATASET:
            TYPE: nuScenes
            ROOT_PATH: /data/Datasets/nuScenes
            INFO_PATH: /data/Datasets/nuScenes/infos_train_10sweeps_withvelo.pkl
            NSWEEPS: 10
        BATCH_SIZE: 5 # 5 for 2080ti, 15 for v100
        ```
        Specify Tasks
        ```
         HEAD:
            TASKS:
                - {num_class: 1, class_names: ["car"]}
                - {num_class: 2, class_names: ["truck", "construction_vehicle"]}
                - {num_class: 2, class_names: ["bus", "trailer"]}
                - {num_class: 1, class_names: ["barrier"]}
                - {num_class: 2, class_names: ["motorcycle", "bicycle"]}
                - {num_class: 2, class_names: ["pedestrian", "traffic_cone"]}
        ```
        
        Run
        ------------
        For better experiments organization, I suggest the following scripts:
        ```
        #!/bin/bash
        TASK_DESC=$1
        DATE_WITH_TIME=`date "+%Y%m%d-%H%M%S"`
        
        OUT_DIR=/data/Outputs/det3d_Outputs
        
        # FOR PointRCNN
        # python -m torch.distributed.launch --nproc_per_node=1 --master_addr="127.0.0.1" --master_port=10121 ./tools/train_rpn.py --config_path=./examples/point_rcnn/configs/car.fhd.kitti.rpn1.prcnn.grid05052.yaml --model_dir=$OUT_DIR/NUSC_SECOND_$TASK_DESC\_$DATE_WITH_TIME
        
        # Voxelnet
        # python -m torch.distributed.launch --nproc_per_node=8 ./examples/voxelnet/train.py --config_path=./examples/voxelnet/configs/ws2.all.nusc.resfhd.rpn2.yaml --model_dir=$OUT_DIR/NUSC_SECOND_$TASK_DESC\_$DATE_WITH_TIME
        # python -m torch.distributed.launch --nproc_per_node=8 ./examples/voxelnet/train.py --config_path=$MODEL_DIR/pipeline.bak.yaml --model_dir=$MODEL_DIR
        
        # PointPillars
        # python -m torch.distributed.launch --nproc_per_node=1 --master_addr="127.0.0.1" --master_port=17777 ./examples/point_pillars/train.py --config_path=./examples/point_pillars/configs/ws2.all.nusc.pp.yaml --model_dir=$OUT_DIR/NUSC_SECOND_$TASK_DESC\_$DATE_WITH_TIME
        
        # PIXOR
        # python -m torch.distributed.launch --nproc_per_node=1 --master_addr="127.0.0.1" --master_port=17777 ./examples/pixor/train.py --config_path=./examples/pixor/configs/ws2.all.nusc.pixor.yaml --model_dir=$OUT_DIR/NUSC_SECOND_$TASK_DESC\_$DATE_WITH_TIME
        ```
        
        ## 4. Currently Support
        * Models
          - [x] VoxelNet
          - [x] SECOND
          - [x] PointtPillars
          - [x] PIXOR
          - [x] SENet & GCNet (GCNet will course model output 0, deprecated.)
          - [x] Pointnet++
          - [x] EKF Tracker & IoU Tracker
          - [x] PointRCNN
        
        * Features
          - [x] Multi task learning
          - [x] Single-gpu & Distributed Training and Validation
          - [x] GradNorm for Multi-task Training
          - [x] Flexible anchor dimensions
          - [x] TensorboardX
          - [x] Checkpointer & breakpoint continue
          - [x] Support both KITTI and nuScenes Dataset
          - [x] SyncBN
          - [x] Self-contained visualization
          - [x] YAML configuration
          - [x] ~~SparseConvNet / MinkowskiEngine ~~
          - [x] OSS Support
          - [x] ImageNet/Objects365/KITTI pretraining : No Effect
          - [x] Finetune
          - [x] Multiscale Training & Validation
          - [x] Rotated RoI Align
        
        
        ## 5. TODO List
        * Models
          - [ ] FrustumPointnet
          - [ ] VoteNet
         
        * Features
        
        
        
Keywords: computer vision,3d object detection
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 2
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
